{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "#old version with a bit issues on gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0828 16:11:45.447479 140518661920576 deprecation.py:323] From <ipython-input-2-8f1fea684f11>:46: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n"
     ]
    }
   ],
   "source": [
    "class NodeLookup(object):\n",
    "    def __init__(self):\n",
    "        label_lookup_path = 'inception_model/imagenet_2012_challenge_label_map_proto.pbtxt'\n",
    "        uid_lookup_path = 'inception_model/imagenet_synset_to_human_label_map.txt'\n",
    "        self.node_lookup = self.load(label_lookup_path, uid_lookup_path)\n",
    "        \n",
    "    def load(self, label_lookup_path, uid_lookup_path):\n",
    "        # 加载分类字符转n*******对应各分类名称的文件\n",
    "        proto_as_ascii_lines = tf.gfile.GFile(uid_lookup_path).readlines()\n",
    "        uid_to_human={}\n",
    "        # 一行一行读取数据\n",
    "        for line in proto_as_ascii_lines:\n",
    "            line = line.strip('\\n')\n",
    "            parsed_items = line.split('\\t')\n",
    "            uid = parsed_items[0]\n",
    "            human_string = parsed_items[1]\n",
    "            uid_to_human[uid] = human_string\n",
    "#         print(uid_to_human)\n",
    "            \n",
    "        # 加载分类字符串n*******对应分类编号1-1000的文件\n",
    "        proto_as_ascii = tf.gfile.GFile(label_lookup_path).readlines()\n",
    "        node_id_to_uid = {}\n",
    "        for line in proto_as_ascii:\n",
    "            if line.strip().startswith('target_class:'):\n",
    "                target_class = int(line.strip().split(':')[1])\n",
    "            elif line.strip().startswith('target_class_'):\n",
    "                target_class_string = line.strip().split(':')[1].strip()\n",
    "                node_id_to_uid[target_class] = target_class_string[1:-1]\n",
    "#         print(node_id_to_uid)\n",
    "        \n",
    "        # 建立分类编号 1-1000 与对应分类名称的映射关系\n",
    "        node_id_to_name = {}\n",
    "        for key,val in node_id_to_uid.items():\n",
    "            name = uid_to_human[val]\n",
    "            node_id_to_name[key] = name\n",
    "        \n",
    "        return node_id_to_name\n",
    "    \n",
    "    # 传入分类编号1-1000 返回分类名称\n",
    "    def id_to_string(self, node_id):\n",
    "        if node_id not in self.node_lookup:\n",
    "            return ''\n",
    "        return self.node_lookup[node_id]\n",
    "            \n",
    "# 创建一个图来存放google训练好的模型\n",
    "with tf.gfile.FastGFile('inception_model/classify_image_graph_def.pb','rb') as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "node_lookup = NodeLookup()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # 拿到softmax的op\n",
    "    # 'softmax:0'这个名字，可以在网络中找到这个节点，它的名字就'(softmax)',\n",
    "    softmax_tensor = sess.graph.get_tensor_by_name('softmax:0')\n",
    "    for root,dirs,files in os.walk('images/'):\n",
    "        for file in files:\n",
    "            image_data = tf.gfile.FastGFile(os.path.join(root,file),'rb').read()\n",
    "            # 运行softmax节点，向其中feed值\n",
    "            # 可以在网络中找到这个名字，DecodeJpeg/contents，\n",
    "            # 据此可以发现，根据名字取网络中op时，如果其名字带括号，就用括号内的名字，如果不带括号，就用右上角介绍的名字。\n",
    "            # 而带个0，是默认情况，如果网络中出现同名节点，这个编号会递增\n",
    "            predictions = sess.run(softmax_tensor,{'DecodeJpeg/contents:0':image_data})\n",
    "            predictions = np.squeeze(predictions)# 把结果转化为1维数据\n",
    "\n",
    "            image_path = os.path.join(root, file)\n",
    "            print(image_path)\n",
    "            img = Image.open(image_path)\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "            # 排序\n",
    "            top_k = predictions.argsort()[-5:][::-1]\n",
    "            for node_id in top_k:\n",
    "                human_string = node_lookup.id_to_string(node_id)\n",
    "                score = predictions[node_id]\n",
    "                print('%s (score = %.5f)' % (human_string, score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
